{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zf-Ut4qtU2XR"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as td\n",
        "import random\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC_fxts3WMRA",
        "outputId": "8d1bf1f1-c8f0-4ea3-8332-0ff98f557a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install xmltodict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ObToxcN-WjdY"
      },
      "outputs": [],
      "source": [
        "import xmltodict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdspINm-Wz0v",
        "outputId": "bfcab6bc-7dd0-4c30-8934-4067e5e73a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gcg5LZeRXAq2"
      },
      "outputs": [],
      "source": [
        "img_names=[] \n",
        "xml_names=[] \n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/archive/'):\n",
        "    for filename in filenames:\n",
        "        if os.path.join(dirname, filename)[-3:]!=\"xml\":\n",
        "            img_names.append(filename)\n",
        "        else:\n",
        "            xml_names.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DuMM3JEXJ69",
        "outputId": "298cb299-8f98-4574-93bc-7d93ae669a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['without_mask', 'with_mask', 'mask_weared_incorrect']) \n",
            " dict_values([717, 3232, 123])\n"
          ]
        }
      ],
      "source": [
        "path_annotations=\"/content/drive/MyDrive/Colab Notebooks/archive/annotations/\" \n",
        "listing=[]\n",
        "for i in img_names[:]:\n",
        "    with open(path_annotations+i[:-4]+\".xml\") as fd:\n",
        "        doc=xmltodict.parse(fd.read())\n",
        "    temp=doc[\"annotation\"][\"object\"]\n",
        "    if type(temp)==list:\n",
        "        for i in range(len(temp)):\n",
        "            listing.append(temp[i][\"name\"])\n",
        "    else:\n",
        "        listing.append(temp[\"name\"])\n",
        "        \n",
        "\n",
        "Items = Counter(listing).keys()\n",
        "values = Counter(listing).values()\n",
        "print(Items,'\\n',values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K7LdHOOaXvIA",
        "outputId": "72963953-92cf-45ad-a670-4a4145e6913e"
      },
      "outputs": [],
      "source": [
        "path_image=\"/content/drive/MyDrive/Colab Notebooks/archive/images/\"  \n",
        "def face_cas(img): \n",
        "    add = True\n",
        "    with open(path_annotations+img[:-4]+\".xml\") as fd:\n",
        "        doc=xmltodict.parse(fd.read())\n",
        "    image=plt.imread(os.path.join(path_image+img))\n",
        "    fig,ax=plt.subplots(1)\n",
        "    ax.axis(\"off\")\n",
        "    fig.set_size_inches(10,5)\n",
        "    temp=doc[\"annotation\"][\"object\"]\n",
        "    mpatch = None;\n",
        "    if type(temp)==list:\n",
        "        for i in range(len(temp)):\n",
        "            ###with_mask\n",
        "            if temp[i][\"name\"]==\"with_mask\":\n",
        "                x,y,w,h=list(map(int,temp[i][\"bndbox\"].values()))\n",
        "                mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor='g',facecolor=\"none\",lw=2,)\n",
        "                ax.add_patch(mpatch)\n",
        "                rx, ry = mpatch.get_xy()\n",
        "                ax.annotate(\"with_mask\", (rx, ry), color='green', weight='bold', fontsize=10, ha='left', va='baseline')\n",
        "            ###without_mask\n",
        "            if temp[i][\"name\"]==\"without_mask\":\n",
        "                x,y,w,h=list(map(int,temp[i][\"bndbox\"].values()))     \n",
        "                mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor='r',facecolor=\"none\",lw=2,)\n",
        "                ax.add_patch(mpatch)\n",
        "                rx, ry = mpatch.get_xy()\n",
        "                ax.annotate(\"without_mask\", (rx, ry), color='red', weight='bold', fontsize=10, ha='left', va='baseline')\n",
        "            ###mask_weared_incorrect\n",
        "            if temp[i][\"name\"]==\"mask_weared_incorrect\":\n",
        "               pass\n",
        "    else:\n",
        "        x,y,w,h=list(map(int,temp[\"bndbox\"].values()))\n",
        "        edgecolor={\"with_mask\":\"g\",\"without_mask\":\"r\"}\n",
        "      \n",
        "        if temp[\"name\"] != \"mask_weared_incorrect\":\n",
        "          add = False\n",
        "          mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor=edgecolor[temp[\"name\"]],facecolor=\"none\",)\n",
        "    ax.imshow(image)\n",
        "    if add and mpatch:\n",
        "      ax.add_patch(mpatch)\n",
        "\n",
        "fun_images = img_names.copy()\n",
        "for i in range(1,8):\n",
        "    face_cas(fun_images[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "MNRgY6csXi0V",
        "outputId": "e195498b-001b-4f39-d552-13c9b3e3826b"
      },
      "outputs": [],
      "source": [
        "options={\"with_mask\":0,\"without_mask\":1,\"mask_weared_incorrect\":2} \n",
        "def dataset_creation(image_list): \n",
        "    image_tensor=[]\n",
        "    label_tensor=[]\n",
        "    for i,j in enumerate(image_list):\n",
        "        with open(path_annotations+j[:-4]+\".xml\") as fd:\n",
        "            doc=xmltodict.parse(fd.read())\n",
        "        if type(doc[\"annotation\"][\"object\"])!=list:\n",
        "            temp=doc[\"annotation\"][\"object\"]\n",
        "            x,y,w,h=list(map(int,temp[\"bndbox\"].values()))\n",
        "            if temp[\"name\"] != \"mask_weared_incorrect\":\n",
        "              label=options[temp[\"name\"]]\n",
        "              image=transforms.functional.crop(Image.open(path_image+j).convert(\"RGB\"), y,x,h-y,w-x)\n",
        "              image_tensor.append(my_transform(image))\n",
        "              label_tensor.append(torch.tensor(label))\n",
        "        else:\n",
        "            temp=doc[\"annotation\"][\"object\"]\n",
        "            for k in range(len(temp)):\n",
        "                x,y,w,h=list(map(int,temp[k][\"bndbox\"].values()))\n",
        "                if temp[k][\"name\"] != \"mask_weared_incorrect\":\n",
        "                  label=options[temp[k][\"name\"]]\n",
        "                  image=transforms.functional.crop(Image.open(path_image+j).convert(\"RGB\"),y,x,h-y,w-x)\n",
        "                  image_tensor.append(my_transform(image))\n",
        "                  label_tensor.append(torch.tensor(label))\n",
        "                \n",
        "    final_dataset=[[k,l] for k,l in zip(image_tensor,label_tensor)]\n",
        "    return tuple(final_dataset)\n",
        "\n",
        "\n",
        "my_transform=transforms.Compose([transforms.Resize((64, 64)),\n",
        "                                 transforms.ToTensor()])\n",
        "\n",
        "mydataset=dataset_creation(img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jruqeqSzX7mu",
        "outputId": "c9ec211f-3a7f-4efe-d63d-0e8024dfd905"
      },
      "outputs": [],
      "source": [
        "train_size=int(len(mydataset)*0.7)\n",
        "test_size=len(mydataset)-train_size\n",
        "print('Length of dataset is', len(mydataset), '\\nLength of training set is :',train_size,'\\nLength of test set is :', test_size)\n",
        "trainset,testset=torch.utils.data.random_split(mydataset,[train_size,test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FbVwofiX8Ra",
        "outputId": "82446a96-9bab-4e7e-9f56-542aa7d34155"
      },
      "outputs": [],
      "source": [
        "train_dataloader =DataLoader(dataset=trainset,batch_size=32,shuffle=True,num_workers=4)\n",
        "test_dataloader =DataLoader(dataset=testset,batch_size=32,shuffle=True,num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "esJHq15UYH39"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
        "                               else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRj98UfTYKRi",
        "outputId": "6ca75532-c8d2-4418-93f5-2f9503e6d31e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEdS4tZjYPFW",
        "outputId": "81e722bb-63be-4c0f-d369-b8ea5d0916bc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "epochs = 10\n",
        "g_lr = 0.0001\n",
        "d_lr = 0.0004\n",
        "beta1 = 0.5\n",
        "ngpu=1\n",
        "\n",
        "def initialize_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "            return output\n",
        "\n",
        "generator = Generator(ngpu).to(device)\n",
        "generator.apply(initialize_weights)\n",
        "print(generator)\n",
        "\n",
        "discriminator = Discriminator(ngpu).to(device)\n",
        "discriminator.apply(initialize_weights)\n",
        "print(discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaKLDhGpeN0j",
        "outputId": "f933a182-8510-479c-8157-4535dcb7a880"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "real_label = 0.9\n",
        "fake_label = 0.1\n",
        "optimizerD = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "g_loss = []\n",
        "d_loss = []\n",
        "loss_func = nn.BCELoss()\n",
        "iters = 0\n",
        "imgs = []\n",
        "train_accuracy = []\n",
        "test_loss = []\n",
        "test_accuracy = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "  \n",
        "        # train with real\n",
        "        discriminator.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "\n",
        "        output = discriminator(real_cpu).view(-1)\n",
        "        errD_real = loss_func(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = generator(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = discriminator(fake.detach()).view(-1)\n",
        "        errD_fake = loss_func(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        \n",
        "        generator.zero_grad()\n",
        "        label.fill_(real_label)  \n",
        "        output = discriminator(fake).view(-1)\n",
        "        errG = loss_func(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        #get train accuracy\n",
        "        image_data, label_data = data[0], data[1]\n",
        "        image_data, label_data = image_data.to(device), label_data.to(device)\n",
        "        discriminator.zero_grad()\n",
        "        real_cpu = images.to(device)\n",
        "        total += label_data.size(0)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "        output = discriminator(real_cpu).view(-1)\n",
        "        output = output.to(device)\n",
        "        correct += (output.view(-1).long() == label_data).sum()\n",
        "\n",
        "\n",
        "        if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(train_dataloader)-1)):\n",
        "          with torch.no_grad():\n",
        "            fixed_noise = torch.randn(ngf, nz, 1, 1, device=device)\n",
        "            fake_display = generator(fixed_noise).detach().cpu()\n",
        "            imgs.append(torchvision.utils.make_grid(fake_display, padding=2, normalize=True))\n",
        "\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "    accuracy = 100 * correct.float() / total\n",
        "    accuracy = accuracy.min().cpu().detach().numpy().tolist()\n",
        "    train_accuracy.append(accuracy)\n",
        "\n",
        "    g_loss.append(errG.item())\n",
        "    d_loss.append(errD.item())  \n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for images, labels in test_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        discriminator.zero_grad()\n",
        "        real_cpu = images.to(device)\n",
        "        total += labels.size(0)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "        output = discriminator(real_cpu).view(-1)\n",
        "        output = output.to(device)\n",
        "        test_error = loss_func(output, labels.float())\n",
        "        correct += (output.view(-1).long() == labels).sum()\n",
        "\n",
        "      \n",
        "    accuracy = 100 * correct.float() / total\n",
        "    accuracy = accuracy.min().cpu().detach().numpy().tolist()\n",
        "    test_accuracy.append(accuracy)\n",
        "    test_loss.append(test_error.item())\n",
        "\n",
        "    print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f' % (epoch+1, epochs, errD.item(), errG.item()))        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "BpMjkwMAeZIc",
        "outputId": "d1c7fdd5-e159-495d-8a2f-dd08362cf276"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(g_loss,label=\"Generator Loss\")\n",
        "plt.plot(d_loss,label=\"Discriminator Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "vK2zAiShviC4",
        "outputId": "a88b7431-988d-4130-ab36-8437e367749f"
      },
      "outputs": [],
      "source": [
        "print(d_loss)\n",
        "print(test_loss)\n",
        "print(train_accuracy)\n",
        "print(test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1qVr60sue92",
        "outputId": "edab2cc6-31c4-4b01-d0d8-0357d7552f63"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ElKp0IWfv8tS",
        "outputId": "57587796-b303-41a8-8a92-e174c21d877d"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.functional import precision_recall\n",
        "correct = 0\n",
        "total = 0\n",
        "total_precision = 0\n",
        "total_recall = 0\n",
        "loss = []\n",
        "for epoch in range(epochs):\n",
        "    for images, labels in test_dataloader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          discriminator.zero_grad()\n",
        "          real_cpu = images.to(device)\n",
        "          total += labels.size(0)\n",
        "          batch_size = real_cpu.size(0)\n",
        "          label = torch.full((batch_size,), real_label, device=device)\n",
        "          output = discriminator(real_cpu).view(-1)\n",
        "          output = output.to(device)\n",
        "          test_error = loss_func(output, labels)\n",
        "          correct += (output.view(-1).long() == labels).sum()\n",
        "          total_precision += precision_recall(output, labels, average='macro', num_classes=1)[0]\n",
        "          total_recall += precision_recall(output, labels, average='macro', num_classes=1)[1]\n",
        "    loss.append(test_error.item())\n",
        "\n",
        "accuracy = 100 * correct.float() / total\n",
        "precision = total_precision / total\n",
        "recall = total_recall / total"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
