{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-01T01:42:43.215220Z","iopub.status.busy":"2022-12-01T01:42:43.214856Z","iopub.status.idle":"2022-12-01T01:42:48.518284Z","shell.execute_reply":"2022-12-01T01:42:48.517526Z","shell.execute_reply.started":"2022-12-01T01:42:43.215118Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os, glob, random, matplotlib, cv2\n","import matplotlib.patches as mplpatches\n","from collections import Counter\n","import pandas as pd\n","from xml.etree import ElementTree as ET\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow_addons as tfa\n","from tensorflow.keras.layers import Dense, Dropout, LayerNormalization\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T01:42:51.230855Z","iopub.status.busy":"2022-12-01T01:42:51.230576Z","iopub.status.idle":"2022-12-01T01:43:01.060297Z","shell.execute_reply":"2022-12-01T01:43:01.059338Z","shell.execute_reply.started":"2022-12-01T01:42:51.230824Z"},"trusted":true},"outputs":[],"source":["!pip install xmltodict"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T01:43:48.595362Z","iopub.status.busy":"2022-12-01T01:43:48.595050Z","iopub.status.idle":"2022-12-01T01:43:48.600039Z","shell.execute_reply":"2022-12-01T01:43:48.599273Z","shell.execute_reply.started":"2022-12-01T01:43:48.595328Z"},"trusted":true},"outputs":[],"source":["import xmltodict"]},{"cell_type":"markdown","metadata":{},"source":["# Load the data <a class=\"anchor\" id=\"loaddata\"></a>"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T01:43:56.501774Z","iopub.status.busy":"2022-12-01T01:43:56.501146Z","iopub.status.idle":"2022-12-01T01:43:56.506039Z","shell.execute_reply":"2022-12-01T01:43:56.505307Z","shell.execute_reply.started":"2022-12-01T01:43:56.501735Z"},"trusted":true},"outputs":[],"source":["annotations_path = \"/kaggle/input/face-mask-detection/annotations\"\n","images_path = \"/kaggle/input/face-mask-detection/images\"\n","\n","CHANNELS = 3\n","IMAGE_SIZE = 224\n","INPUT_SIZE = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n","TRAIN_SET_PRCNT = 0.70"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T01:43:58.571850Z","iopub.status.busy":"2022-12-01T01:43:58.571285Z","iopub.status.idle":"2022-12-01T01:43:58.582893Z","shell.execute_reply":"2022-12-01T01:43:58.582138Z","shell.execute_reply.started":"2022-12-01T01:43:58.571811Z"},"trusted":true},"outputs":[],"source":["def get_annotation(annotation_file):\n","    \n","    objects = {\n","            \"xmin\":[],\n","            \"ymin\":[],   \n","            \"xmax\":[],\n","            \"ymax\":[],\n","            \"name\":[],    \n","            \"file\":[],\n","            \"width\":[],\n","            \"height\":[],\n","           }\n","\n","    tree = ET.parse(annotation_file)\n","\n","    for el in tree.iter():\n","        if 'size' in el.tag:\n","            for attr in list(el):\n","                if 'width' in attr.tag: \n","                    width = int(round(float(attr.text)))\n","                if 'height' in attr.tag:\n","                    height = int(round(float(attr.text)))    \n","\n","        if 'object' in el.tag:\n","            for attr in list(el):\n","\n","                if 'name' in attr.tag:\n","                    name = attr.text\n","                    if name == \"mask_weared_incorrect\":\n","                        name == \"with_mask\"\n","                    \n","                    if name == \"with_mask\":\n","                        name = 1\n","                    else:\n","                        name = 0\n","                    objects['name']+=[name]\n","                    objects['width']+=[width]\n","                    objects['height']+=[height] \n","                    objects['file']+=[annotation_file.split('/')[-1][0:-4]] \n","\n","                if 'bndbox' in attr.tag:\n","                    for dim in list(attr):\n","                        if 'xmin' in dim.tag:\n","                            xmin = int(round(float(dim.text)))\n","                            objects['xmin']+=[xmin]\n","                        if 'ymin' in dim.tag:\n","                            ymin = int(round(float(dim.text)))\n","                            objects['ymin']+=[ymin]                                \n","                        if 'xmax' in dim.tag:\n","                            xmax = int(round(float(dim.text)))\n","                            objects['xmax']+=[xmax]                                \n","                        if 'ymax' in dim.tag:\n","                            ymax = int(round(float(dim.text)))\n","                            objects['ymax']+=[ymax]     \n","    \n","    return objects\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-01T01:44:01.623104Z","iopub.status.busy":"2022-12-01T01:44:01.622838Z"},"trusted":true},"outputs":[],"source":["image_files = [\n","    f for f in os.listdir(images_path) if os.path.isfile(os.path.join(images_path, f))\n","]\n","annot_files = [\n","    f for f in os.listdir(annotations_path) if os.path.isfile(os.path.join(annotations_path, f))\n","]\n","\n","image_files.sort()\n","annot_files.sort()\n","\n","images, targets = [], []\n","vals = []\n","\n","for i in range(0, len(annot_files)):\n","    annot = get_annotation(os.path.join(annotations_path, annot_files[i]))\n","\n","    top_left_x, top_left_y = annot['xmax'], annot['ymax']\n","    bottom_right_x, bottom_right_y = annot['xmin'], annot['ymin']\n","\n","    image = keras.utils.load_img(\n","        os.path.join(images_path, image_files[i]),\n","    )\n","    (w, h) = image.size[:2]\n","    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n","\n","    for i in range(0, len(top_left_x)):\n","        images.append(keras.utils.img_to_array(image))\n","        targets.append(\n","            (                \n","                float(top_left_x[i]) / w,\n","                float(top_left_y[i]) / h,\n","                float(bottom_right_x[i]) / w,\n","                float(bottom_right_y[i]) / h,\n","                \n","            )\n","        )\n","        vals.append(annot[\"name\"])\n","        \n","    \n","t = []\n","    \n","for i in range(len(vals)):\n","    for j in range(len(vals[i])):\n","        t.append(vals[i][j])\n","    \n","'''\n","    t.append(vals[i])\n","    \n","    one = 0\n","    zero = 0\n","    for j in range(len(targets[i])):\n","        if targets[i][j] == 1:\n","            one += 1\n","        else:\n","            zero += 1\n","    \n","    if one > zero:\n","        t.append(1)\n","    else:\n","        t.append(0)\n","    '''\n","\n","    \n","(x_train), (y_train) = (\n","    np.asarray(images[: int(len(images) * TRAIN_SET_PRCNT)]),\n","    np.asarray(t[: int(len(t) * TRAIN_SET_PRCNT)]).astype('float32'),\n",")\n","\n","(x_test), (y_test) = (\n","    np.asarray(images[int(len(images) * TRAIN_SET_PRCNT) :]),\n","    np.asarray(t[int(len(t) * TRAIN_SET_PRCNT) :]).astype('float32'),\n",")\n","\n","imgs = []\n","\n","for i in range(len(x_train)):\n","    x = x_train[i]\n","    top_left_x, top_left_y = int(targets[i][0]* 224), int(targets[i][1] * 224)\n","    bottom_right_x, bottom_right_y = int(targets[i][2] * 224), int(targets[i][3] * 224)\n","    img = x[bottom_right_y:top_left_y, bottom_right_x:top_left_x]\n","    shape = img.shape\n","    xDiff = 244-shape[0]\n","    xLeft = xDiff//2\n","    xRight = xDiff-xLeft\n","\n","    yDiff = 244-shape[1]\n","    yLeft = yDiff//2\n","    yRight = yDiff - yLeft\n","    \n","    imgs.append(np.pad(img,((xLeft,xRight),(yLeft,yRight),(5,5)), mode='constant'))\n","    \n","for i in range(len(x_test)):\n","    x = x_test[i]\n","    top_left_x, top_left_y = int(targets[i + len(x_train)][0]* 224), int(targets[i + len(x_train)][1] * 224)\n","    bottom_right_x, bottom_right_y = int(targets[i + len(x_train)][2] * 224), int(targets[i + len(x_train)][3] * 224)\n","    \n","    img = x[bottom_right_y:top_left_y, bottom_right_x:top_left_x]\n","    shape = img.shape\n","    xDiff = 244-shape[0]\n","    xLeft = xDiff//2\n","    xRight = xDiff-xLeft\n","\n","    yDiff = 244-shape[1]\n","    yLeft = yDiff//2\n","    yRight = yDiff - yLeft\n","    \n","    imgs.append(np.pad(img,((xLeft,xRight),(yLeft,yRight),(5,5)), mode='constant'))\n","\n","imgs = np.asarray(imgs)\n","\n","(x_train) = np.asarray(imgs[: int(len(imgs) * TRAIN_SET_PRCNT)])\n","\n","\n","(x_test) = np.asarray(imgs[int(len(imgs) * TRAIN_SET_PRCNT) :])\n","\n","'''\n","x = x_train[0]\n","fig, ax1 = plt.subplots(1, figsize=(3,3))\n","top_left_x, top_left_y = int(y_train[i][0]* 224), int(y_train[i][1] * 224)\n","bottom_right_x, bottom_right_y = int(y_train[i][2] * 224), int(y_train[i][3] * 224)\n","box_predicted = [top_left_x, top_left_y, bottom_right_x, bottom_right_y]\n","\n","im = x[bottom_right_y:top_left_y, bottom_right_x:top_left_x]\n","print(box_predicted)\n","# Display the image\n","ax1.imshow(im.astype(\"uint8\"))\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_image = x_train[0]\n","fig, ax1 = plt.subplots(1, figsize=(15, 15))\n","im = input_image\n","ax1.imshow(im.astype(\"uint8\"))\n","\n","\n","input_image = cv2.resize(\n","    input_image, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA\n",")\n","(h, w) = (im).shape[0:2]\n","\n","for i in range(0,3):\n","    top_left_x, top_left_y = int(y_train[i][0] * 224), int(y_train[i][1] * 224)\n","    bottom_right_x, bottom_right_y = int(y_train[i][2] * 224), int(y_train[i][3] * 224)\n","    box_predicted = [top_left_x, top_left_y, bottom_right_x, bottom_right_y]\n","    rect = mplpatches.Rectangle(\n","                            (top_left_x, top_left_y),\n","                            bottom_right_x - top_left_x,\n","                            bottom_right_y - top_left_y,\n","                            facecolor=\"none\",\n","                            edgecolor=\"red\",\n","                            linewidth=1,\n","                        )\n","    print(box_predicted)\n","    ax1.add_patch(rect)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","SEED = 42\n","DROPOUT = 0.1\n","NUM_HEADS = 8\n","PADDING = \"VALID\"\n","EPSILON = 1e-6\n","EPOCHS = 10\n","PATCH_SIZE = 32\n","NUM_LAYERS = 10\n","WEIGHT_DECAY = 1e-4\n","BATCH_SIZE = 4\n","MLP_DIM = 128\n","PROJECTION_DIM = 64\n","LR = 1e-6"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update(\n","            {\n","                \"input_shape\": input_shape,\n","                \"patch_size\": patch_size,\n","                \"num_patches\": num_patches,\n","                \"projection_dim\": projection_dim,\n","                \"num_heads\": num_heads,\n","                \"transformer_units\": transformer_units,\n","                \"transformer_layers\": transformer_layers,\n","                \"mlp_head_units\": mlp_head_units,\n","            }\n","        )\n","        return config\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=PADDING,\n","        )\n","        return tf.reshape(patches, [batch_size, -1, patches.shape[-1]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["random_num = random.randint(0, len(x_train)-1)\n","\n","plt.figure(figsize=(4, 4))\n","plt.imshow(x_train[random_num]/255.)\n","plt.axis(\"off\")\n","\n","patches = Patches(PATCH_SIZE)(tf.convert_to_tensor([x_train[random_num]]))\n","print(f\"Image size: {IMAGE_SIZE} X {IMAGE_SIZE}\")\n","print(f\"Patch size: {PATCH_SIZE} X {PATCH_SIZE}\")\n","print(f\"{patches.shape[1]} patches per image \\n{patches.shape[-1]} elements per patch\")\n","\n","\n","n = int(np.sqrt(patches.shape[1]))\n","plt.figure(figsize=(6, 6))\n","\n","for i, patch in enumerate(patches[0]):\n","    ax = plt.subplot(n, n, i + 1)\n","    patch_img = tf.reshape(patch, (PATCH_SIZE, PATCH_SIZE, CHANNELS))\n","    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update(\n","            {\n","                \"input_shape\": input_shape,\n","                \"patch_size\": patch_size,\n","                \"num_patches\": num_patches,\n","                \"projection_dim\": projection_dim,\n","                \"num_heads\": num_heads,\n","                \"transformer_units\": transformer_units,\n","                \"transformer_layers\": transformer_layers,\n","                \"mlp_head_units\": mlp_head_units,\n","            }\n","        )\n","        return config\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_vit_object_detector(\n","                                input_shape,\n","                                patch_size,\n","                                num_patches,\n","                                projection_dim,\n","                                num_heads,\n","                                transformer_units,\n","                                transformer_layers,\n","                                mlp_head_units):\n","    \n","    \n","    inputs = layers.Input(shape=input_shape)\n","    patches = Patches(PATCH_SIZE)(inputs)\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    for _ in range(transformer_layers):\n","        x1 = layers.LayerNormalization(epsilon=EPSILON)(encoded_patches)\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=DROPOUT\n","        )(x1, x1)\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        x3 = layers.LayerNormalization(epsilon=EPSILON)(x2)\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=DROPOUT)\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    representation = layers.LayerNormalization(epsilon=EPSILON)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(DROPOUT*3)(representation)\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=DROPOUT*3)\n","\n","    bounding_box = layers.Dense(1)(features)\n","\n","    return keras.Model(inputs=inputs, outputs=bounding_box)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.python.client import device_lib\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')), \"\\n\")\n","\n","print(device_lib.list_local_devices())\n","\n","tf.debugging.set_log_device_placement(True)\n","tf.random.set_seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras import backend as K\n","from tensorflow.keras.optimizers import SGD\n","\n","class BalancedSparseCategoricalAccuracy(keras.metrics.SparseCategoricalAccuracy):\n","    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n","        super().__init__(name, dtype=dtype)\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_flat = y_true\n","        if y_true.shape.ndims == y_pred.shape.ndims:\n","            y_flat = tf.squeeze(y_flat, axis=[-1])\n","        y_true_int = tf.cast(y_flat, tf.int32)\n","\n","        cls_counts = tf.math.bincount(y_true_int)\n","        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n","        weight = tf.gather(cls_counts, y_true_int)\n","        return super().update_state(y_true, y_pred, sample_weight=weight)\n","\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def train(model, learning_rate, weight_decay, batch_size, num_epochs):\n","\n","    optimizer = tfa.optim.SGD(learning_rate, weight_decay)\n","\n","    \n","    model.compile(\n","                    optimizer=optimizer, \n","                    loss=['binary_crossentropy'],\n","                    metrics=['acc',f1_m,precision_m, recall_m]\n","                  )\n","    \n","    checkpoint_filepath = \"logs/\"\n","    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","        checkpoint_filepath,\n","        monitor=\"val_loss\",\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","    class_weight = {0: 0.51, 1: 0.48}\n","    tr = model.fit(\n","                            x=x_train,\n","                            y=y_train,\n","                            batch_size=batch_size,\n","                            epochs=num_epochs,\n","                            validation_split=0.25,\n","                            class_weight= class_weight,\n","                            callbacks=[\n","                                        checkpoint_callback,\n","                                        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n","                                      ],\n","                         )\n","\n","    return tr\n","\n","\n","num_patches = (IMAGE_SIZE // PATCH_SIZE) ** 2\n","\n","transformer_units = [\n","                        PROJECTION_DIM * 2,\n","                        PROJECTION_DIM,\n","                    ]\n","\n","transformer_layers = 6\n","mlp_head_units = [2048, 1024, 512, 64, 32]\n","\n","\n","history = []\n","num_patches = (IMAGE_SIZE // PATCH_SIZE) ** 2\n","\n","vit_object_detector = create_vit_object_detector(\n","                                                    INPUT_SIZE,\n","                                                    PATCH_SIZE,\n","                                                    num_patches,\n","                                                    PROJECTION_DIM,\n","                                                    NUM_HEADS,\n","                                                    transformer_units,\n","                                                    transformer_layers,\n","                                                    mlp_head_units,\n","                                                )"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize ViT model <a class=\"anchor\" id=\"visualize\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vit_object_detector.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","plot_model(vit_object_detector, to_file='model.png')"]},{"cell_type":"markdown","metadata":{},"source":["## Training the model <a class=\"anchor\" id=\"fitting\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train model\n","for i in range(5):\n","    print(f\"Test {i + 1}\")\n","    train(vit_object_detector, LR, WEIGHT_DECAY, BATCH_SIZE, 10)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate <a class=\"anchor\" id=\"future\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Evaluate on test data\")\n","test_loss, test_acc, f1, precision, recall = vit_object_detector.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n","print(\"test loss: \", test_loss)\n","print(\"test acc: \", test_acc)\n","print(\"f1: \", f1)\n","print(\"precision: \", precision)\n","print(\"recall: \", recall)\n","\n","acc_ones = 0\n","acc_zeroes = 0\n","pre_ones = 0\n","pre_zeroes = 0\n","correct = 0\n","\n","for i in y_test:\n","    if i == 1:\n","        acc_ones += 1\n","    else:\n","        acc_zeroes += 1\n","\n","for index, i in enumerate(vit_object_detector.predict(x_test)):\n","    if i > 0.5:\n","        pre_ones += 1\n","        if y_test[index] == 1:\n","            correct += 1\n","    else:\n","        if y_test[index] == 0:\n","            correct += 1\n","            print(True)\n","        pre_zeroes += 1\n","        \n","\n","print(correct/len(y_test))        \n","print(acc_ones, acc_zeroes)\n","print(pre_ones, pre_zeroes)\n","\n","con = tf.math.confusion_matrix(labels=y_test, predictions=vit_object_detector.predict(x_test))\n","print(con)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
